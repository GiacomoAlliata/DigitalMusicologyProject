{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2 - Data gathering and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Narrowing down the research question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this research project we will try to analyse a corpus of popular songs to try to identify  chords differences between verses and choruses. We will try to  answer the following research questions :\n",
    "<ol>\n",
    "<li>Does the chord distribution of the choruses differ from the one in the verses?</li>\n",
    "<li>Is there a different chord sequence distribution in the choruses compared to the verses?</li>\n",
    "<li>How are these distributions evolving over time? </li>\n",
    "</ol>\n",
    "\n",
    "In the first question we want to know if a difference exists in terms of chords statistic. Are we more likely to find a specific chord in the choruses? Are fewer different chords used in the chorus compared to the other parts of a song? <br> \n",
    "For the second one we want to have a more melodic insight. Can we find specific patterns? Is the Markov model derived from the chorus different from its counterparts? <br>\n",
    "In the third one the focus is on the time dimension. We want to know if the results of the two previous answers change over time. Were chorus closer to verses in 1968 than in 1985? How does each chord evolve in relation to the others? Do we find a sequence that appeared while other disappeared? \n",
    "\n",
    "These are all the underlying questions we want to answer under our main research questions.  \n",
    "\n",
    "These questions relate to our original idea to fully characterize a chorus over the years, especially in comparison with verses. We now want to focus specifically on the chords to differentiate these different parts, while keeping the temporal dimension as a potential factor to observe changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give us the means to answer our questions, we have selected a dataset containing approximately 900 Pop-Rock songs in the top Billboard charts from the 60s to the 90s. They are simple text files with the following informations : \n",
    "* Release date\n",
    "* Song title \n",
    "* Artist name\n",
    "* Labels for the different parts of the song (such as chorus or verse)\n",
    "* Timestamp of each musical phrase beginning\n",
    "* Chords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the chorus/verse annotations to classify the chords in each group. This will allow us to divide the chords in two groups and compute statistics and distributions for each of them. As discussed in the research questions, we will start with a basic characterization, simply comparing which chords appear in which section. We will then move deeper and compare the distributions of chords as well as the Markov models. These will be computed at least with bigrams, perhaps with higher-n n-grams depending on the number of chords in each section (as it makes little sense to use n-grams with n close to the number of chords in a given section).\n",
    "\n",
    "The metadata, especially the release date, will be used to study the evolution over time of the previously discussed statistics. Depending on the distribution of songs over the years, time analysis will be discussed either over years or over decades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible outcomes and confidence measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different outcomes we can reasonably expect are: \n",
    "<ul>\n",
    "    <li> <strong>Null results:</strong> There are no significant differences between choruses and verses and no evolution over time. This could be explained by a bias in the corpus toward a specific Pop-Rock genre using the same chords all the time or maybe there is indeed no difference in the chords used in a chorus and the ones used in verses, which would constitute an answer for our questions. </li>\n",
    "<li> <strong>Narrow chorus chord distribution:</strong> Since the chorus has to be immediately recognized as one, maybe the composers make more extensive use of a sub group of the chords to ensure it. The same reasoning could be applied to the chord sequences: perhaps some specific ones will be more dominant in the chorus.</li>\n",
    "<li> <strong>Temporal evolution:</strong> It will be interesting to see if the differences between verse and chorus change over the years. This evolution, if present, could be linear or oscillating. A linear narrowing would imply that choruses are becoming more and more similar or verse more and more diverse. An oscillating pattern would be interesting as musical phenomenon could appear and disappear.</li>\n",
    "</ul>\n",
    "\n",
    "Statistical tests will be used throughtout our analysis to check if our findings are statistically relevant. Error bars will also be included in all our graphics to avoid wrong conclusions. Of course the relative small size of our corpus will influence our results but only further analysis can reveal if significant results can still be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gathering the data\n",
    "The dataset has been created by [1] and corresponds to a random sample of 890 Billboard chart slots presented at ISMIR 2011 and MIREX 2012. Due to the nature of the sampling algorithm, there are some duplicates and this results in only 740 distinct songs. According to the authors, training algorithms that assume independent, identically distributed data should retain the duplicates.<br> This dataset is publicly available at https://ddmal.music.mcgill.ca/research/The_McGill_Billboard_Project_(Chord_Analysis_Dataset)/ and can be downloaded in various formats. Different features are given by the authors. In this project we will use metadata and chords annotations. \n",
    "The first dataset used is the index to the dataset (csv format), containing the following fields:\n",
    "<ul>\n",
    "<li><b>id</b>, the index for the sample entry.</li>\n",
    "<li><b>chart_date</b>, the date of the chart for the entry.</li>\n",
    "<li><b>target_rank</b>, the desired rank on that chart.</li>\n",
    "<li><b>actual_rank</b>, the rank of the song actually annotated, which may be up to 2 ranks higher or lower than the target rank [1, 2].</li>\n",
    "<li><b>title</b>, the title of the song annotated.</li>\n",
    "<li><b>artist</b>, the name of the artist performing the song annotated.</li>\n",
    "<li><b>peak_rank</b>, the highest rank the song annotated ever achieved on the Billboard Hot 100.</li>\n",
    "<li><b>weeks_on_chart</b>, the number of weeks the song annotated spent on the Billboard Hot 100 chart in total.</li>\n",
    "</ul>\n",
    "\n",
    "The main dataset comprehends chords, structure, instrumentation, and timing, given in a txt format. The annotation for each song begins with a header containing the title of the song, the name of the artist, the metre and the tonic pitch class of the opening key. In the main body, each line consists of a single phrase and begins with its timestamp, followed by the chords. This requires us to design a specific parser, as will be discussed in the next section.<br>\n",
    "We downloaded the two datasets which constitutes the whole of their database so we have the maximum from this source. It is not excluded that we find some additional ones to perform further analysis. As for now we will try to get as much stastitically relevant information from this source.\n",
    "\n",
    "[1]: John Ashley Burgoyne, Jonathan Wild, and Ichiro Fujinaga, ‘An Expert Ground Truth Set for Audio Chord Recognition and Music Analysis’, in Proceedings of the 12th International Society for Music Information Retrieval Conference, ed. Anssi Klapuri and Colby Leider (Miami, FL, 2011), pp. 633–38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this question is to load the data and have a look at it. A specific parser is designed to do this automatically, in order to extract and store in a Pandas dataframe all the relevant informations and musical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(theme='white')\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(\"data/billboard-2.0-index.csv\")\n",
    "metadata_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are %d entries in the index table.' %len(metadata_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are %d entries with a given title.' %metadata_df.title.isna().value_counts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are %d entries with a given artist.' %metadata_df.artist.isna().value_counts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are %d entries with a given chart date.' %metadata_df.chart_date.isna().value_counts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = {'01':'January', \n",
    "          '02':'February',\n",
    "          '03':'March',\n",
    "          '04':'April',\n",
    "          '05':'May',\n",
    "          '06':'June',\n",
    "          '07':'July',\n",
    "          '08':'August',\n",
    "          '09':'September',\n",
    "          '10':'October',\n",
    "          '11':'November',\n",
    "          '12':'December'}\n",
    "def format_date(date):\n",
    "    year = date[:4]\n",
    "    month = date[5:7]\n",
    "    day = date[-2:]\n",
    "    if day == '01':\n",
    "        suffix = 'st'\n",
    "    elif day == '02':\n",
    "        suffix = 'nd'\n",
    "    elif day == '03':\n",
    "        suffix = 'rd'\n",
    "    else:\n",
    "        suffix = 'th'\n",
    "        \n",
    "    if day[0] == '0':\n",
    "        day = day[1]\n",
    "    \n",
    "    date_string = months[month] + ' ' + day + suffix + ', ' + year\n",
    "    return(date_string)\n",
    "\n",
    "#Test\n",
    "format_date('1958-08-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The songs range from %s to %s.' %(format_date(metadata_df.chart_date.min()), format_date(metadata_df.chart_date.max())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SONG_ID, LINE_NUMBER, MEASURE_NUMBER, CHORD_NUMBER, SEQUENCE_NUMBER, \\\n",
    "CHORD, INSTRUMENT, TYPE, TIME, STRUCTURE, DURATION, REPETITION, ELID = \\\n",
    "\"song_id\",\"line_id\", \"measure_id\", \"chord_id\", \"sequence_id\",\\\n",
    "\"chord\", \"instrument\", \"section_type\", \"time\", \"section_structure\", \"duration\", \"repetition\", \"elided\"\n",
    "\n",
    "#This is dependant of \"metre\" in the txt files.\n",
    "METRE = \"metre\"\n",
    "\n",
    "#Create a new dictionary from two other\n",
    "def immutable_merge(dic1, dic2):\n",
    "    result = dic1.copy()\n",
    "    result.update(dic2)\n",
    "    return result\n",
    "\n",
    "#Create a row of the futur df as a dictionary\n",
    "def create_row(persistent_attributes, line_attributes,\n",
    "               measure_number = None, chord_number = None, chord = None, duration = None):\n",
    "    result = immutable_merge(persistent_attributes, line_attributes)\n",
    "    \n",
    "    if not (measure_number is None and measure_number is None and chord_number is None and duration is None):\n",
    "        result[MEASURE_NUMBER] = measure_number\n",
    "        result[CHORD_NUMBER] = chord_number\n",
    "        result[CHORD] = chord\n",
    "        result[DURATION] = duration\n",
    "    \n",
    "    return result\n",
    "\n",
    "#Generate the attributes of a given line and update the sequence counter\n",
    "def process_line_metadata(header, line_counter, old_line_attributes, sequence_counter, suffix = \"\"):\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    #Suffix (main instrument, elid, repetition)\n",
    "    old_instrument = str(old_line_attributes.get(INSTRUMENT))\n",
    "    \n",
    "    for suffix in suffix.split(\", \"):\n",
    "        \n",
    "        suffix = suffix.strip()\n",
    "        \n",
    "        #Repetition\n",
    "        if re.match(\"^x\\d+$\",suffix):\n",
    "            result[REPETITION] = int(suffix[1])\n",
    "        \n",
    "        #Elid\n",
    "        elif suffix == \"->\":\n",
    "            result[ELID] = True\n",
    "\n",
    "        #Instrument\n",
    "        else:\n",
    "            ##New instrument\n",
    "            if len(suffix) > 0 and suffix != \"\\n\":\n",
    "                result[INSTRUMENT] = suffix.strip(\"\\n\").strip(\",\").strip()\n",
    "\n",
    "            ##Main instrument continued (experimental)\n",
    "            elif not old_instrument.endswith(\")\") and old_instrument.lower() not in [\"nan\",\"none\"] \\\n",
    "            and len(old_instrument)>0:\n",
    "                result[INSTRUMENT] = old_instrument.strip(\"(\")\n",
    "\n",
    "        \n",
    "    #Line number\n",
    "    result[LINE_NUMBER] = line_counter\n",
    "\n",
    "    \n",
    "    #Header    \n",
    "    header_items = header.split()\n",
    "        \n",
    "    result[TIME] = header_items[0]\n",
    "    \n",
    "    #Case where a section is continued\n",
    "    if len(header_items) == 1:\n",
    "        result[TYPE] = old_line_attributes.get(TYPE)\n",
    "        result[STRUCTURE] = old_line_attributes.get(STRUCTURE)\n",
    "        result[SEQUENCE_NUMBER] = old_line_attributes.get(SEQUENCE_NUMBER)\n",
    "    \n",
    "    #Case where a section has no structure (silence, end, fadeout)\n",
    "    elif len(header_items) == 2:\n",
    "        \n",
    "        #Z is a structure, not a type.\n",
    "        if header_items[1].strip().strip(\",\") == \"Z\":\n",
    "            result[STRUCTURE] = header_items[1].strip().strip(\",\")\n",
    "        else:\n",
    "            result[TYPE] = header_items[1].strip().strip(\",\")\n",
    "            \n",
    "        result[SEQUENCE_NUMBER] = sequence_counter\n",
    "        sequence_counter += 1\n",
    "    \n",
    "    #Case where a section begins.\n",
    "    elif len(header_items) == 3:\n",
    "        result[STRUCTURE] = header_items[1].strip().strip(\",\")\n",
    "        result[TYPE] = header_items[2].strip().strip(\",\")\n",
    "        result[SEQUENCE_NUMBER] = sequence_counter\n",
    "        sequence_counter += 1\n",
    "    \n",
    "    return sequence_counter, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_song_to_dict(song_id, path):\n",
    "    \n",
    "    rows = []\n",
    "    persistent_attributes = {}\n",
    "    \n",
    "    persistent_attributes[SONG_ID] = song_id\n",
    "    \n",
    "    with open(path,\"r\") as file:\n",
    "        line = file.readline()\n",
    "        \n",
    "        line_counter = 0\n",
    "        measure_counter = 0\n",
    "        chord_counter = 0\n",
    "        sequence_counter = 0\n",
    "        line_attributes = {}\n",
    "        old_chord = None\n",
    " \n",
    "\n",
    "        while line:\n",
    "        \n",
    "            if line != \"\\n\":\n",
    "\n",
    "                #Attribute lines\n",
    "                if line.startswith(\"#\"):\n",
    "                    attribute, value = line.strip(\"#\").split(\":\",1)\n",
    "                    persistent_attributes[attribute.strip(\" \")] = value.strip(\" \").strip(\"\\n\")\n",
    "\n",
    "                else:\n",
    "                    line_items = line.split(\"|\")\n",
    "\n",
    "                    #Special lines\n",
    "                    if len(line_items) <= 1:\n",
    "                        sequence_counter, line_attributes = \\\n",
    "                        process_line_metadata(line, line_counter, line_attributes, sequence_counter)\n",
    "                        row = create_row(persistent_attributes, line_attributes)\n",
    "                        rows.append(row)\n",
    "\n",
    "                    #Standard lines    \n",
    "                    else:                    \n",
    "                        header = line_items[0]\n",
    "                        suffix = line_items[-1]\n",
    "                        measures = line_items[1:-1]\n",
    "\n",
    "                        sequence_counter, line_attributes = \\\n",
    "                        process_line_metadata(header, line_counter, line_attributes, sequence_counter, suffix)  \n",
    "\n",
    "                        for measure in measures:\n",
    "                            \n",
    "                            chords = measure.split()\n",
    "                            \n",
    "                            #Special metric (experimental)\n",
    "                            old_metre = persistent_attributes.get(METRE)\n",
    "                            if re.match(\"^\\(\\d/\\d\\)$\", chords[0]):\n",
    "                                persistent_attributes[METRE] = str(chords[0][1]) + \"/\" + str(chords[0][3])\n",
    "                                chords = chords[1:]\n",
    "                            \n",
    "                            if len(chords) == 1:\n",
    "                                duration = \"measure\"\n",
    "                            elif len(chords) == 2 and persistent_attributes[METRE] in [\"4/4\",\"12/8\"]:\n",
    "                                duration = \"half-measure\"\n",
    "                            else:\n",
    "                                duration = \"beat\"\n",
    "                            \n",
    "                            for chord in chords:\n",
    "                                \n",
    "                                if chord == \".\":\n",
    "                                    chord = old_chord\n",
    "                                \n",
    "                                row = create_row(persistent_attributes, line_attributes,\n",
    "                                                 measure_counter, chord_counter, chord, duration)\n",
    "                                rows.append(row)\n",
    "                                old_chord = chord\n",
    "                                chord_counter += 1\n",
    "\n",
    "                            measure_counter += 1\n",
    "                            persistent_attributes[METRE] = old_metre\n",
    "            \n",
    "            #Finally\n",
    "            line_counter += 1\n",
    "            line = file.readline()\n",
    "    \n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(parse_song_to_dict(0,\"data/McGill-Billboard/0004/salami_chords.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_whole_collection_df():\n",
    "    \n",
    "    path = \"data/McGill-Billboard/\"\n",
    "    file_name = \"/salami_chords.txt\"\n",
    "    UPPER_BOUND = 1300\n",
    "    \n",
    "    whole_collection = []\n",
    "    \n",
    "    i = 0\n",
    "    while i <= UPPER_BOUND:\n",
    "        full_path = path + \"0\"*(4-len(str(i)))+ str(i) + file_name\n",
    "        \n",
    "        if os.path.exists(full_path):\n",
    "            whole_collection += parse_song_to_dict(i, full_path)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    whole_collection_df = pd.DataFrame(whole_collection)\n",
    "    \n",
    "    return whole_collection_df.astype({SEQUENCE_NUMBER: 'Int64', MEASURE_NUMBER: 'Int64', CHORD_NUMBER: 'Int64', \\\n",
    "                                      REPETITION: 'Int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df = create_whole_collection_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df.set_index(\"song_id\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUGS: Point = répétition du même accord? A élucider et modifier. DONE\n",
    "# Il y a des mesures à un seul accord, d'autres à un accord par temps. A prendre en compte ! DONE\n",
    "#Introduire un sequence_id qui identifie un chorus, un verse, etc... DONE\n",
    "#Signalétique indiquant une répétition (x) ou un elid (->) à prendre en compte (colonne instrument) DONE\n",
    "#Dans certains morceaux, il y a des mesures au metre différent du metre principal, indiqué entre (). DONE\n",
    "#La lettre Z est parfois classée comme \"type\", parfois comme \"structure\" DONE\n",
    "#Certaines mesures contiennent deux accords de durée d'une demi-mesure DONE\n",
    "\n",
    "#&pause est de taille arbitraire, pas forcément une mesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your dataset and show examples of how you access the information that you are interested in.\n",
    "Give an overview of your dataset by plotting some basic statistics of the relevant features and/or metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=metadata_df.chart_date.map(lambda y:pd.to_datetime(y).year).value_counts(sort=False)\n",
    "years.iplot(kind='bar', title=\"Number of sample song per year\", xTitle=\"Year\", yTitle=\"Samples\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df.chord.value_counts().head(24).iplot(kind='bar',title=\"Overall chord occurence ditribution\",xTitle=\"Chord\",yTitle=\"Occurence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df[collection_df[\"section_type\"]==\"chorus\"].chord.value_counts().head(20).iplot(kind='bar',title=\"Chorus chord occurence ditribution\",xTitle=\"Chord\",yTitle=\"Occurence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic statistics: Number of unique chords per songs\n",
    "unique_chord_songs = collection_df[[SONG_ID,CHORD]].drop_duplicates().groupby(SONG_ID).count()\n",
    "n_bins = int(unique_chord_songs.max())+1\n",
    "unique_chord_songs.plot.hist(bins = n_bins, legend = False)\n",
    "plt.title('Distribution of the number of unique chords per song', fontsize = 20)\n",
    "plt.xlabel('Number of unique chord', fontsize = 18)\n",
    "plt.ylabel('Frequency', fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df[\"time\"]=collection_df.time.apply(lambda y: int(float(y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze function\n",
    "#### with examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The squeeze function returns a dataframe with the all the chords of a song squeezed in a row dependent on a subgroup\n",
    "# of the section type. Default is \"none\" and will not filter any type of songs.\n",
    "#try subgroup=\"chorus\" or subgroup=\"verse\"\n",
    "\n",
    "def compress(s) :\n",
    "    return s.dropna().to_list()\n",
    "\n",
    "def squeeze(df,subgroup=\"none\"):\n",
    "    df_local=df\n",
    "    if(subgroup!=\"none\"):\n",
    "        df_local=df[df[\"section_type\"]==subgroup]\n",
    "        \n",
    "    return pd.DataFrame(df_local.groupby([\"song_id\",\"title\"]).chord.agg(compress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squeeze section allows you to squeeze the sections of songs, t\n",
    "\n",
    "\n",
    "def squeeze_section(df,subgroup=\"none\"):\n",
    "    df_local=df\n",
    "    if(subgroup!=\"none\"):\n",
    "        df_local=df[df[\"section_type\"]==subgroup]\n",
    "        \n",
    "    return pd.DataFrame(df_local.groupby([\"song_id\",\"sequence_id\",\"section_type\"]).chord.agg(compress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeeze_section(collection_df).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov=squeeze(collection_df)\n",
    "markov.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeeze(collection_df,\"chorus\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bigrams\n",
    "\n",
    "def bigrams_seq(seq):\n",
    "    return list(zip(seq[:-1], seq[1:]))\n",
    "\n",
    "def bigrams_corpus(seqs):\n",
    "    return [bg for seq in seqs for bg in bigrams_seq(seq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov[\"bigrams\"]=markov.chord.map(lambda y : bigrams_seq(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=markov.bigrams.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_one=Counter(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_two=markov.bigrams.iloc[2]\n",
    "c_two=Counter(test_two)\n",
    "added=c_two+c_one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser for the chords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Split a string and changes the target field depending on which side of the split to take\n",
    "#side : 0 for left and 1 for right\n",
    "def split_add(c,dic,split_char,target,side):\n",
    "    temp=str.split(str(c),split_char)\n",
    "\n",
    "    dic[target]=temp[side]\n",
    "    return dic, temp[1-side]\n",
    "\n",
    "\n",
    "def chord_to_tab(c):\n",
    "    c=str(c)\n",
    "    chord={\"root\":\"\", \"shorthand\" : \"\", \"degree_list\":[], \"bass\":\"\", \"N\" :False}\n",
    "    rest=\"\"\n",
    "    \n",
    "    if(c==\"N\"):\n",
    "        chord[\"N\"] = True\n",
    "        return chord\n",
    "    \n",
    "    c=c.replace(\")\",\"\")\n",
    "    \n",
    "    if('/' in c):\n",
    "        chord, rest=split_add(c,dic=chord,split_char=\"/\",target=\"bass\",side=1)\n",
    "    else :\n",
    "        rest=c\n",
    "    if(':' in rest):\n",
    "        chord, rest=split_add(rest,dic=chord,split_char=\":\",target=\"root\",side=0)\n",
    "    if('(' in rest):\n",
    "        chord, rest=split_add(rest,dic=chord,split_char=\"(\",target=\"degree_list\",side=1)\n",
    "    if(rest != \"\"):\n",
    "        chord[\"shorthand\"]=rest\n",
    "    \n",
    "    return chord\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df[\"chord_dic\"]=collection_df.chord.map(lambda y : chord_to_tab(y))\n",
    "collection_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how to access the dic :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df.chord_dic.map(lambda y: y[\"root\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df.chord_dic.map(lambda y: y[\"N\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorhand=['maj','min','dim','aug','maj7','min7', '7','dim7','hdim7'\n",
    "'minmaj7','maj6', 'min6','9', 'maj9', 'min9','sus4','11','maj11','min11','maj13','min13','sus2']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelques graphs avec le nouveau dico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#il faut encore que je vire l'élément vide\n",
    "collection_df.chord_dic.map(lambda y: y[\"root\"]).value_counts().iplot(kind=\"bar\", title=\"chord distribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df.chord_dic.map(lambda y: y[\"shorthand\"]).value_counts().iplot(kind=\"bar\", title=\"Type d'accord\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df.chord_dic.map(lambda y: y[\"bass\"]).value_counts()[1:].plot(kind=\"bar\",title=\"bass note distribution\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tonic and duration analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of new dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of new columns fo relative-to-tonic roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chord_dic_to_columns(df):\n",
    "    for key in ['root','shorthand','degree_list','bass','N']:\n",
    "        df[\"{}\".format(key)] = df.chord_dic.apply(lambda x : x.get(key))\n",
    "        \n",
    "    df.drop(columns = [\"chord_dic\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df = chord_dic_to_columns(collection_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPC_DIC = {\"Cb\":11,\"C\":0,\"C#\":1,\"Db\":1,\"D\":2,\"D#\":3,\"Eb\":3,\"E\":4,\"E#\":5,\"Fb\":4,\"F\":5,\"F#\":6,\n",
    "           \"Gb\":6,\"G\":7,\"G#\":8,\"Ab\":8,\"A\":9,\"A#\":10,\"Bb\":10,\"B\":11,\"B#\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df[\"root_tpc\"] = collection_df.root.apply(lambda r : TPC_DIC.get(r))\n",
    "collection_df = collection_df.astype({\"root_tpc\":\"Int64\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df[\"relative_root_tpc\"] =\\\n",
    "collection_df.apply(lambda row: (row[\"root_tpc\"] - TPC_DIC.get(row[\"tonic\"]))%12,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df = collection_df.fillna({REPETITION:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duration tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration of measure: all metre in the corpus are regular except song 700 (5/8 = 3 + 2). This was counted as two beats.\n",
    "\n",
    "Creation of a one-row-per-beat dataframe (Need all cells of this section to work properly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_row(metre, duration, repetition):\n",
    "    \"\"\"\n",
    "    Indicate to how many beats in total a chord described on a dataframe's row correspond.\n",
    "    Careful ! The chords are non-successive in case of repetition\n",
    "    \"\"\"\n",
    "    num, denom = metre.split(\"/\")\n",
    "    \n",
    "    if metre == \"5/8\": #Specific to this dataset\n",
    "        beat_per_measure = 2\n",
    "    else:\n",
    "        beat_per_measure = int(num)/(1 if int(denom) == 4 else 3)\n",
    "    \n",
    "    if duration == \"measure\":\n",
    "        return beat_per_measure*(repetition)\n",
    "    \n",
    "    elif duration == \"half-measure\":\n",
    "        return beat_per_measure/2*(repetition)\n",
    "    \n",
    "    elif duration == \"beat\":\n",
    "        return repetition\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def successive_repetition_row(metre,duration):\n",
    "    \"\"\"\n",
    "    Indicate on how many successive beats a chord is present\n",
    "    \"\"\"\n",
    "    return weight_row(metre,duration,repetition=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of df with only song with both verse and chorus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_songs = collection_df[[SONG_ID,TYPE]].drop_duplicates().groupby(SONG_ID)[TYPE].apply(list)\\\n",
    ".apply(lambda l: \"chorus\" in l and \"verse\" in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_collection_df = collection_df.merge(valid_songs.reset_index().rename(columns = {TYPE:\"valid\"}),on = SONG_ID)\n",
    "d_collection_df = d_collection_df[d_collection_df.valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of one-row-per-bit dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of one-row-per-bit dataframe\n",
    "N_SUCC_BEATS = \"n_succ_beats\"\n",
    "\n",
    "d_collection_df[N_SUCC_BEATS] = d_collection_df.apply(\\\n",
    "    lambda row: successive_repetition_row(row[METRE], row[DURATION]),axis=1)\n",
    "d_collection_df = d_collection_df.astype({N_SUCC_BEATS:\"Int64\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def create_beats_df(d_collection_df):\n",
    "    beats_dics = []\n",
    "    repetition_flag = False\n",
    "    repeted_dics = []\n",
    "    repetition_line = np.PINF\n",
    "    repetition_song = np.PINF\n",
    "    for i in tqdm(d_collection_df.reset_index().index):\n",
    "\n",
    "        if repetition_flag == True and\\\n",
    "(repetition_line != d_collection_df.iloc[i][LINE_NUMBER] or repetition_song != d_collection_df.iloc[i][SONG_ID]):\n",
    "\n",
    "            for r in range(repetition_n):\n",
    "                beats_dics += repeted_dics\n",
    "\n",
    "            repetition_flag = False\n",
    "            repeted_dics = []\n",
    "            repetition_line = np.PINF\n",
    "            repetition_song = np.PINF\n",
    "        \n",
    "        \n",
    "        if d_collection_df.iloc[i][REPETITION] == 1 :\n",
    "\n",
    "            for b in range(d_collection_df.iloc[i][N_SUCC_BEATS]):\n",
    "                beats_dics.append(d_collection_df.iloc[i].to_dict())\n",
    "\n",
    "        else:\n",
    "\n",
    "            repetition_flag = True\n",
    "            repetition_line = d_collection_df.iloc[i][LINE_NUMBER]\n",
    "            repetition_song = d_collection_df.iloc[i][SONG_ID]\n",
    "            repetition_n = d_collection_df.iloc[i][REPETITION]\n",
    "\n",
    "            for b in range(d_collection_df.iloc[i][N_SUCC_BEATS]):\n",
    "                repeted_dics.append(d_collection_df.iloc[i].to_dict())\n",
    "\n",
    "    beats_collection_df = pd.DataFrame(beats_dics)\n",
    "    \n",
    "    return beats_collection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beats_collection_df = create_beats_df(d_collection_df)\n",
    "beats_collection_df = beats_collection_df.drop(N_SUCC_BEATS,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chorus/verse proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the distribution of the proportion of beats in a song that belong to choruses, respectively to verses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_WEIGHT = \"total_weight\"\n",
    "\n",
    "\n",
    "d_collection_df[TOTAL_WEIGHT] = d_collection_df.apply(\\\n",
    "    lambda row: weight_row(row[METRE], row[DURATION], row[REPETITION]),axis=1)\n",
    "\n",
    "d_collection_df[N_SUCC_BEATS] =  d_collection_df.apply(\\\n",
    "    lambda row: successive_repetition_row(row[METRE], row[DURATION]),axis=1)\n",
    "\n",
    "d_collection_df = d_collection_df.astype({TOTAL_WEIGHT: 'Int64',N_SUCC_BEATS: 'Int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_beat_chorus = d_collection_df[d_collection_df.section_type == \"chorus\"].groupby(\"song_id\")[TOTAL_WEIGHT].sum()\\\n",
    ".reset_index().rename(columns= {TOTAL_WEIGHT:\"chorus_weight\"})\n",
    "n_beat_verse = d_collection_df[d_collection_df.section_type == \"verse\"].groupby(\"song_id\")[TOTAL_WEIGHT].sum()\\\n",
    ".reset_index().rename(columns= {TOTAL_WEIGHT:\"verse_weight\"})\n",
    "n_beat = d_collection_df.groupby(\"song_id\")[TOTAL_WEIGHT].sum()\n",
    "\n",
    "#Considering only songs with both chorus and verse. For all song, use line below\n",
    "# n_beat_chorus.merge(n_beat_verse,on=\"song_id\",how=\"outer\").merge(n_beat,on=\"song_id\",how=\"outer\").fillna(0)\n",
    "proportions_df = n_beat_chorus.merge(n_beat_verse,on=\"song_id\").merge(n_beat,on=\"song_id\")\n",
    "\n",
    "proportions_df[\"chorus_weight\"] = proportions_df[\"chorus_weight\"]/proportions_df[\"total_weight\"]\n",
    "proportions_df[\"verse_weight\"] = proportions_df[\"verse_weight\"]/proportions_df[\"total_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions_df[[\"chorus_weight\",\"verse_weight\"]].describe().drop(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can observe is that the distributions of choruses and verses share similar statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tonic Proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_collection_df[[SONG_ID,\"tonic\"]].drop_duplicates().groupby(\"tonic\")\\\n",
    ".count().rename(columns = {SONG_ID:\"number_of_songs\"}).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-chord tonic distance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From now, we consider d_collection_df, that contains only songs that share a chorus and a verse\n",
    "\n",
    "def per_chord_tonic_distance_analysis(distance,df,n_beat_type,btype):\n",
    "    \"\"\"\n",
    "    Create weighted mean and std of chord distance to tonic and describe them\n",
    "    \n",
    "    distance: measure of distance, for exemple relative tpc from the tonic\n",
    "    df: dataframe to consider\n",
    "    n_beat_type: dataframe that give for each song the number of beat (= number of chords) for given type\n",
    "    btype: name of the column in n_beat_type\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"weight*dist\"] =df[distance]*df[TOTAL_WEIGHT]\n",
    "    mean_numerator_df = df.groupby(SONG_ID)[\"weight*dist\"].sum().reset_index()\\\n",
    "    .rename(columns = {\"weight*dist\":\"mean_numerator\"})\n",
    "    \n",
    "    \n",
    "    agg_df = mean_numerator_df.merge(n_beat_type, on = \"song_id\")\n",
    "    agg_df[\"mean_distance\"] = agg_df[\"mean_numerator\"]/agg_df[btype]\n",
    "    \n",
    "    #Need mean to compute variance\n",
    "    df = df.merge(agg_df[[\"mean_distance\",\"song_id\"]], on = \"song_id\")\n",
    "    \n",
    "    df[\"variance_item\"] = (df[\"weight*dist\"] - df[TOTAL_WEIGHT]*df[\"mean_distance\"])\\\n",
    "    .apply(lambda x : np.power(x,2))\n",
    "    variance_numerator_df = df.groupby(SONG_ID)[\"variance_item\"].sum().reset_index()\\\n",
    "    .rename(columns = {\"variance_item\":\"variance_numerator\"})\n",
    "    \n",
    "    agg_df = agg_df.merge(variance_numerator_df, on = \"song_id\")\n",
    "    agg_df[\"variance_distance\"] = agg_df[\"variance_numerator\"]/agg_df[btype]\n",
    "    agg_df[\"std_distance\"] = agg_df[\"variance_distance\"].apply(np.sqrt)\n",
    "    \n",
    "    return agg_df.describe()[[\"mean_distance\",\"std_distance\"]]\n",
    "    \n",
    "    return mean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_per_chord_tonic_distance_analysis(distance,df):\n",
    "    chorus_distance_df = df[df.section_type == \"chorus\"]\n",
    "    verse_distance_df = df[df.section_type == \"verse\"]\n",
    "    \n",
    "    n_beat_chorus = df[df.section_type == \"chorus\"].groupby(\"song_id\")[TOTAL_WEIGHT].sum()\\\n",
    "    .reset_index().rename(columns= {TOTAL_WEIGHT:\"chorus_weight\"})\n",
    "    n_beat_verse = df[df.section_type == \"verse\"].groupby(\"song_id\")[TOTAL_WEIGHT].sum()\\\n",
    "    .reset_index().rename(columns= {TOTAL_WEIGHT:\"verse_weight\"})\n",
    "    \n",
    "    print(\"Choruses\")\n",
    "    print(per_chord_tonic_distance_analysis(distance,chorus_distance_df,n_beat_chorus,\"chorus_weight\"))\n",
    "    print()\n",
    "    print(\"Verses\")\n",
    "    print(per_chord_tonic_distance_analysis(distance,verse_distance_df,n_beat_verse,\"verse_weight\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_per_chord_tonic_distance_analysis(\"relative_root_tpc\",d_collection_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are currently not very interesting, but we might choose a different measure of distance, for example related to how we perceive chords or to the tonal hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Musical path analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we explore the melodic lines of music by investigating how the distance to tonic evolve along the time dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Squeeze with repetition\n",
    "def weighted_squeeze(df,col):\n",
    "    \"\"\"\n",
    "    Recreate a line with one chord per beat\n",
    "    \"\"\"\n",
    "    df[\"chord_sublist\"] = df.apply(lambda row: row[N_SUCC_BEATS]*[row[col]],axis = 1)\n",
    "    \n",
    "    line_df = df.groupby([SONG_ID,TYPE,LINE_NUMBER,])[\"chord_sublist\"].sum().reset_index()\n",
    "    \n",
    "    \n",
    "    #line_df[\"chord_sublist\"] = line_df[\"chord_sublist\"].apply(lambda l: np.array(l).flatten())\n",
    "    \n",
    "    \n",
    "    return line_df.rename(columns = {\"chord_sublist\":\"chord_list\"})\n",
    "    \n",
    "def full_squeeze(df,col):\n",
    "    \"\"\"\n",
    "    Recreate a section, considering repetitions of full lines.\n",
    "    \"\"\"\n",
    "    #Not implemented yet\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df = weighted_squeeze(d_collection_df,\"relative_root_tpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_path(line_df,line_length,verbose=True):\n",
    "    \"\"\"\n",
    "    Show mean path for given line length\n",
    "    \"\"\"\n",
    "    \n",
    "    f = plt.figure(figsize=(12,4))\n",
    "    \n",
    "    means_dic = {}\n",
    "    \n",
    "    for i, section_type in enumerate((\"chorus\",\"verse\")):\n",
    "        \n",
    "        f.add_subplot(1,2,i+1)\n",
    "        \n",
    "        sample_df = line_df[line_df[\"chord_list\"].apply(lambda l: len(l) == line_length)]\n",
    "\n",
    "        sample_df = sample_df[sample_df[TYPE] == section_type]\n",
    "        \n",
    "        means = pd.DataFrame(sample_df[\"chord_list\"].values.tolist()).mean(axis = 0)\n",
    "        means_dic[section_type] = means\n",
    "        \n",
    "        if verbose:\n",
    "            print(len(sample_df),\"lines considered for\",section_type)\n",
    "\n",
    "            means.plot.bar()\n",
    "            plt.title(\"Average relative root tpc for lines of length {} in {}\".format(line_length,section_type))\n",
    "            plt.xlabel(\"Position of chord\")\n",
    "            plt.ylabel(\"Avg relative root tpc\")\n",
    "    \n",
    "    \n",
    "    if not verbose:\n",
    "        return means_dic    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_path(line_df,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General shape, number of non-tonic chords between two tonic chords, evolution of tonic distance depending on note position, etc\n",
    "#Considérer les LIGNES mélodiques. Faire des analyses sur chaque ligne de longueur X pour toutes les longueurs possibles\n",
    "# Il faudrait faire la même chose avec les sections entières"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_path(df,distance,line_len):\n",
    "    line_df = weighted_squeeze(df,distance)\n",
    "    mean_path(line_df,line_len)\n",
    "    \n",
    "def plot_section_path(df,distance,sec_len):\n",
    "    sec_df = full_squeeze(df,distance)\n",
    "    mean_path(sec_df,sec_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests with different distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance between tonic and root of chord, in semi-tone up or down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_collection_df[\"tpc_distance\"] = d_collection_df[\"relative_root_tpc\"].apply(lambda tpc: min(tpc,12-tpc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_per_chord_tonic_distance_analysis(\"tpc_distance\",d_collection_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_path(d_collection_df,\"tpc_distance\",8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concordance distance (manual mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This small proximity attribution is done following the proximity graph of course 9 (slide 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concordance_dic = {0:15,7:5,5:2.5,9:2.5,1:2.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_collection_df[\"concordance_proximity\"] = d_collection_df[\"relative_root_tpc\"]\\\n",
    ".apply(lambda r: concordance_dic.get(r))\n",
    "\n",
    "d_collection_df = d_collection_df.fillna({\"concordance_proximity\":1}).dropna(subset = [\"relative_root_tpc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_per_chord_tonic_distance_analysis(\"concordance_proximity\",d_collection_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_line_path(d_collection_df,\"concordance_proximity\",8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests (DO NOT INCLUDE IN MERGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_beat_verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chorus_distance_df[\"weight*dist\"] =chorus_distance_df[\"relative_root_tpc\"]*chorus_distance_df[TOTAL_WEIGHT]\n",
    "chorus_distance_df[\"mean_distance\"] = chorus_distance_df[\"weight*dist\"].groupby(SONG_ID).sum()/n_beat_chorus\n",
    "chorus_distance_df[\"variance_distance\"] = chorus_distance_df[\"weight*dist\"] - \\\n",
    "    chrous_distance_df[TOTAL_WEIGHT]*chorus_distance_df[\"mean_distance\"]\n",
    "\n",
    "verse_distance_df[\"weight*dist\"] =verse_distance_df[\"relative_root_tpc\"]*verse_distance_df[TOTAL_WEIGHT]\n",
    "verse_distance_df[\"mean_distance\"] = chorus_distance_df[\"weight*dist\"].groupby(SONG_ID).sum()/n_beat_verse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_distance = df.groupby(SONG_ID)[\"weight*dist\"].sum()[full_mask]/n_beat_type[btype]\n",
    "    #df = df.merge(df.groupby(SONG_ID)[\"weight*dist\"].sum().reset_index()\\\n",
    "    #              .rename(columns = {\"weight*dist\":\"mean_numerator\"}),on = \"song_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering songs that have the wanted section (UNUSED)\n",
    "full_mask=\\\n",
    "c_collection_df.groupby(\"song_id\")[\"section_type\"].apply(list).apply(lambda l: \"chorus\" in l and \"verse\" in l)\n",
    "chorus_mask = c_collection_df.groupby(\"song_id\")[\"section_type\"].apply(list).apply(lambda l: \"chorus\" in l)\n",
    "verse_mask = c_collection_df.groupby(\"song_id\")[\"section_type\"].apply(list).apply(lambda l: \"verse\" in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3*[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_collection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[[3,4]]]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_collection_df.groupby(SONG_ID)[\"tonic\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chorus_distance_df = c_collection_df[c_collection_df.section_type == \"chorus\"]\\\n",
    "[[SONG_ID,\"relative_root_tpc\",TOTAL_WEIGHT]]\n",
    "verse_distance_df = c_collection_df[c_collection_df.section_type == \"verse\"]\\\n",
    "[[SONG_ID,\"relative_root_tpc\",TOTAL_WEIGHT]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_collection_df[[\"song_id\",REPETITION]][d_collection_df[REPETITION]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(beats_collection_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_collection_df.iloc[10000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_collection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_collection_df[N_SUCC_BEATS].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "beats_collection_df[(beats_collection_df[SONG_ID] == 34) & (beats_collection_df[\"section_structure\"] == \"D\")].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = d_collection_df[d_collection_df[SONG_ID] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = create_beats_df(test_df)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[REPETITION] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = create_beats_df(test_df)\n",
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[REPETITION] = 3\n",
    "test_df[test_df.section_structure == \"B\"][REPETITION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
